{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nfLVy1PaGoZL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from tweepy) (3.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.11)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-win_amd64.whl (8.7 MB)\n",
      "Collecting numpy>=1.15.4\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-win_amd64.whl (13.2 MB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "Successfully installed numpy-1.19.5 pandas-1.1.5 pytz-2022.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Import appropriate libraries\n",
    "\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "#Define Access Keys\n",
    "\n",
    "api_key = 't7U9rmjmbvqZCQnherHkrDZ9q'\n",
    "api_key_secret = 'k5FwX8KGxruNp9oUlhNCb1xHtJ1JjIIlI7ozai5vGaMM2pIaCU'\n",
    "\n",
    "access_token = '1532526934269239303-nQpMFHharyoQCfc8FoNuUwAUFdJM6Y'\n",
    "access_token_secret = 'ndON5Ktl0MEOFDtjGMjGVkuRz4D6FWpaPruh2IHUWEgC0'\n",
    "\n",
    "# authentication\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fkR-rEPwGpIr",
    "outputId": "32e907cd-660f-42e0-f85a-b00521b8c684"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nRitoyBjL4tz",
    "outputId": "7d172a9b-5794-4b17-8fe2-063c256771f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120218 entries, 0 to 120217\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   User     120217 non-null  object\n",
      " 1   Tweet    120218 non-null  object\n",
      " 2   Label    120218 non-null  object\n",
      " 3   Title    120218 non-null  object\n",
      " 4   Country  120218 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 4.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Import corpus csv\n",
    "\n",
    "df_final = pd.read_csv(\"Corpus_Final.csv\")\n",
    "\n",
    "print(df_final.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "V6-uMYwzL4xT"
   },
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanUpTweet(txt):\n",
    "    # Remove mentions\n",
    "    txt = re.sub(r'@+', '', txt)\n",
    "    # Remove hashtags\n",
    "    txt = re.sub(r'#[A-Z0-9]+', '', txt)\n",
    "    # Remove retweets:\n",
    "    txt = re.sub(r'RT : ', '', txt)\n",
    "    # Remove urls\n",
    "    txt = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', txt)\n",
    "    #remove amp\n",
    "    txt = re.sub(r'&amp;', '', txt)\n",
    "    #rempve strange characters\n",
    "    txt = re.sub(r'ðŸ™', '', txt)\n",
    "    #remove new lines\n",
    "    txt = re.sub(r'\\n', ' ', txt)\n",
    "    return txt\n",
    "\n",
    "df_final['Cleaned_Tweet'] = df_final['Tweet'].apply(cleanUpTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZjadLExrL41F",
    "outputId": "080d9bcd-799c-44f7-e219-9619548b09fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "      <th>Title</th>\n",
       "      <th>Country</th>\n",
       "      <th>Cleaned_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>I didn't ask for a pardon.\\n\\nBut a certain Pr...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>I didn't ask for a pardon.  But a certain Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>Your daily reminder that instead of saying som...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>Your daily reminder that instead of saying som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>I’m proud to work with my Congressional collea...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>I’m proud to work with my Congressional collea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>RT @grantstern: Multiple Republican Congressme...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>RT grantstern: Multiple Republican Congressmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>RT @MacFarlaneNews: Approx. 140 police officer...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>RT MacFarlaneNews: Approx. 140 police officers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       User                                              Tweet Label Title  \\\n",
       "0  RepAdams  I didn't ask for a pardon.\\n\\nBut a certain Pr...     D   HOR   \n",
       "1  RepAdams  Your daily reminder that instead of saying som...     D   HOR   \n",
       "2  RepAdams  I’m proud to work with my Congressional collea...     D   HOR   \n",
       "3  RepAdams  RT @grantstern: Multiple Republican Congressme...     D   HOR   \n",
       "4  RepAdams  RT @MacFarlaneNews: Approx. 140 police officer...     D   HOR   \n",
       "\n",
       "  Country                                      Cleaned_Tweet  \n",
       "0      US  I didn't ask for a pardon.  But a certain Pres...  \n",
       "1      US  Your daily reminder that instead of saying som...  \n",
       "2      US  I’m proud to work with my Congressional collea...  \n",
       "3      US  RT grantstern: Multiple Republican Congressmen...  \n",
       "4      US  RT MacFarlaneNews: Approx. 140 police officers...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tVtfwXjJNe_i",
    "outputId": "d78f247e-c2ce-42bd-e850-279d67c29ff1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "      <th>Title</th>\n",
       "      <th>Country</th>\n",
       "      <th>Cleaned_Tweet</th>\n",
       "      <th>Label_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>I didn't ask for a pardon.\\n\\nBut a certain Pr...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>I didn't ask for a pardon.  But a certain Pres...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>Your daily reminder that instead of saying som...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>Your daily reminder that instead of saying som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>I’m proud to work with my Congressional collea...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>I’m proud to work with my Congressional collea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>RT @grantstern: Multiple Republican Congressme...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>RT grantstern: Multiple Republican Congressmen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>RT @MacFarlaneNews: Approx. 140 police officer...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>RT MacFarlaneNews: Approx. 140 police officers...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       User                                              Tweet Label Title  \\\n",
       "0  RepAdams  I didn't ask for a pardon.\\n\\nBut a certain Pr...     D   HOR   \n",
       "1  RepAdams  Your daily reminder that instead of saying som...     D   HOR   \n",
       "2  RepAdams  I’m proud to work with my Congressional collea...     D   HOR   \n",
       "3  RepAdams  RT @grantstern: Multiple Republican Congressme...     D   HOR   \n",
       "4  RepAdams  RT @MacFarlaneNews: Approx. 140 police officer...     D   HOR   \n",
       "\n",
       "  Country                                      Cleaned_Tweet  Label_Number  \n",
       "0      US  I didn't ask for a pardon.  But a certain Pres...             1  \n",
       "1      US  Your daily reminder that instead of saying som...             1  \n",
       "2      US  I’m proud to work with my Congressional collea...             1  \n",
       "3      US  RT grantstern: Multiple Republican Congressmen...             1  \n",
       "4      US  RT MacFarlaneNews: Approx. 140 police officers...             1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode Label: D = 1 / R = 0\n",
    "\n",
    "df_final['Label_Number'] = df_final.Label.map({'R':0, 'D':1})\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "ufkVboIGL44G",
    "outputId": "1fafbf96-8e1a-408b-993c-c1df629a40fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">User</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Tweet</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Label</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Title</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Country</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Cleaned_Tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>...</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label_Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59522</td>\n",
       "      <td>120</td>\n",
       "      <td>RepFischbach</td>\n",
       "      <td>500</td>\n",
       "      <td>59523</td>\n",
       "      <td>58662</td>\n",
       "      <td>There still is a crisis at the border.</td>\n",
       "      <td>10</td>\n",
       "      <td>59523</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>HOR</td>\n",
       "      <td>35523</td>\n",
       "      <td>59523</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>59523</td>\n",
       "      <td>59523</td>\n",
       "      <td>58041</td>\n",
       "      <td></td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60695</td>\n",
       "      <td>123</td>\n",
       "      <td>SenatorSinema</td>\n",
       "      <td>500</td>\n",
       "      <td>60695</td>\n",
       "      <td>59741</td>\n",
       "      <td>RT @rosadelauro: The infant formula shortage c...</td>\n",
       "      <td>16</td>\n",
       "      <td>60695</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>HOR</td>\n",
       "      <td>36695</td>\n",
       "      <td>60695</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>60695</td>\n",
       "      <td>60695</td>\n",
       "      <td>59339</td>\n",
       "      <td></td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               User                             Tweet         \\\n",
       "              count unique            top freq  count unique   \n",
       "Label_Number                                                   \n",
       "0             59522    120   RepFischbach  500  59523  58662   \n",
       "1             60695    123  SenatorSinema  500  60695  59741   \n",
       "\n",
       "                                                                      Label  \\\n",
       "                                                            top freq  count   \n",
       "Label_Number                                                                  \n",
       "0                        There still is a crisis at the border.   10  59523   \n",
       "1             RT @rosadelauro: The infant formula shortage c...   16  60695   \n",
       "\n",
       "                     ... Title        Country                   Cleaned_Tweet  \\\n",
       "             unique  ...   top   freq   count unique top   freq         count   \n",
       "Label_Number         ...                                                        \n",
       "0                 1  ...   HOR  35523   59523      1  US  59523         59523   \n",
       "1                 1  ...   HOR  36695   60695      1  US  60695         60695   \n",
       "\n",
       "                              \n",
       "             unique top freq  \n",
       "Label_Number                  \n",
       "0             58041      334  \n",
       "1             59339      222  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.groupby('Label_Number').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from scikit-learn->sklearn) (1.5.4)\n",
      "Installing collected packages: sklearn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\danca\\\\anaconda3\\\\envs\\\\Arkenews\\\\Lib\\\\site-packages\\\\sklearn-0.0.dist-info\\\\INSTALLEResti2w2w.tmp'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.2-cp36-cp36m-win_amd64.whl (423.3 MB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from tensorflow) (0.37.1)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\tarfile.py\", line 2273, in utime\n",
      "    os.utime(targetpath, (tarinfo.mtime, tarinfo.mtime))\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\danca\\\\AppData\\\\Local\\\\Temp\\\\pip-install-eiyp_av1\\\\wrapt_dfb37ee308494fc1a1374030184c4895\\\\setup.py'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 173, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 203, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 316, in run\n",
      "    reqs, check_supported_wheels=not options.target_dir\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 95, in resolve\n",
      "    collected.requirements, max_rounds=try_to_avoid_resolution_too_deep\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 472, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 366, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 212, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 203, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 140, in __bool__\n",
      "    return any(self)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 128, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 32, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 209, in _make_candidate_from_link\n",
      "    version=version,\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 301, in __init__\n",
      "    version=version,\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 227, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 306, in _prepare_distribution\n",
      "    self._ireq, parallel_builds=True\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 508, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 552, in _prepare_linked_requirement\n",
      "    self.download_dir, hashes\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 249, in unpack_url\n",
      "    unpack_file(file.path, location, file.content_type)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\unpacking.py\", line 256, in unpack_file\n",
      "    untar_file(filename, location)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\unpacking.py\", line 230, in untar_file\n",
      "    tar.utime(member, path)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\tarfile.py\", line 2275, in utime\n",
      "    raise ExtractError(\"could not change modification time\")\n",
      "tarfile.ExtractError: could not change modification time\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 365, in __exit__\n",
      "    if cb(*exc_details):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 284, in _exit_wrapper\n",
      "    return cm_exit(cm, *exc_details)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 165, in __exit__\n",
      "    self.cleanup()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 184, in cleanup\n",
      "    rmtree(self._path)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 326, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 406, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 362, in iter\n",
      "    raise retry_exc.reraise()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 195, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 425, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 384, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 409, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 135, in rmtree\n",
      "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 500, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 395, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 393, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\danca\\\\AppData\\\\Local\\\\Temp\\\\pip-unpack-4mlqaj9n\\\\wrapt-1.12.1.tar.gz'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 365, in __exit__\n",
      "    if cb(*exc_details):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 284, in _exit_wrapper\n",
      "    return cm_exit(cm, *exc_details)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 165, in __exit__\n",
      "    self.cleanup()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 184, in cleanup\n",
      "    rmtree(self._path)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 326, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 406, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 362, in iter\n",
      "    raise retry_exc.reraise()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 195, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 425, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 384, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 409, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 135, in rmtree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 500, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 395, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 393, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\danca\\\\AppData\\\\Local\\\\Temp\\\\pip-install-eiyp_av1\\\\wrapt_dfb37ee308494fc1a1374030184c4895\\\\setup.py'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 365, in __exit__\n",
      "    if cb(*exc_details):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 284, in _exit_wrapper\n",
      "    return cm_exit(cm, *exc_details)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 165, in __exit__\n",
      "    self.cleanup()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 184, in cleanup\n",
      "    rmtree(self._path)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 326, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 406, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 362, in iter\n",
      "    raise retry_exc.reraise()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 195, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 425, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 384, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 409, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 135, in rmtree\n",
      "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 500, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 395, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 393, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\danca\\\\AppData\\\\Local\\\\Temp\\\\pip-unpack-050ly769\\\\Keras_Preprocessing-1.1.2-py2.py3-none-any.whl'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 365, in __exit__\n",
      "    if cb(*exc_details):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 284, in _exit_wrapper\n",
      "    return cm_exit(cm, *exc_details)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 165, in __exit__\n",
      "    self.cleanup()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 184, in cleanup\n",
      "    rmtree(self._path)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 326, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 406, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 362, in iter\n",
      "    raise retry_exc.reraise()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 195, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 425, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 384, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 409, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 135, in rmtree\n",
      "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 500, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 395, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 393, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\danca\\\\AppData\\\\Local\\\\Temp\\\\pip-unpack-4dlorvws\\\\absl_py-0.15.0-py3-none-any.whl'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 365, in __exit__\n",
      "    if cb(*exc_details):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 284, in _exit_wrapper\n",
      "    return cm_exit(cm, *exc_details)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 165, in __exit__\n",
      "    self.cleanup()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 184, in cleanup\n",
      "    rmtree(self._path)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 326, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 406, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 362, in iter\n",
      "    raise retry_exc.reraise()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 195, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 425, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 384, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 409, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 135, in rmtree\n",
      "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 500, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 395, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 393, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\danca\\\\AppData\\\\Local\\\\Temp\\\\pip-unpack-9ez8qxrv\\\\astunparse-1.6.3-py2.py3-none-any.whl'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 365, in __exit__\n",
      "    if cb(*exc_details):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 284, in _exit_wrapper\n",
      "    return cm_exit(cm, *exc_details)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 165, in __exit__\n",
      "    self.cleanup()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 184, in cleanup\n",
      "    rmtree(self._path)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 326, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 406, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 362, in iter\n",
      "    raise retry_exc.reraise()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 195, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 425, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 384, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 409, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 135, in rmtree\n",
      "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 500, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 395, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 393, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\danca\\\\AppData\\\\Local\\\\Temp\\\\pip-unpack-gj1_oitj\\\\tensorflow-2.6.2-cp36-cp36m-win_amd64.whl'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\Scripts\\pip-script.py\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\cli\\main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 98, in main\n",
      "    return self._main(args)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 88, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\cli\\command_context.py\", line 20, in main_context\n",
      "    yield\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 380, in __exit__\n",
      "    raise exc_details[1]\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 99, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 75, in tempdir_registry\n",
      "    yield _tempdir_registry\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 365, in __exit__\n",
      "    if cb(*exc_details):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 284, in _exit_wrapper\n",
      "    return cm_exit(cm, *exc_details)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 88, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 37, in global_tempdir_manager\n",
      "    _tempdir_manager = old_tempdir_manager\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 380, in __exit__\n",
      "    raise exc_details[1]\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 365, in __exit__\n",
      "    if cb(*exc_details):\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\contextlib.py\", line 284, in _exit_wrapper\n",
      "    return cm_exit(cm, *exc_details)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 165, in __exit__\n",
      "    self.cleanup()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 184, in cleanup\n",
      "    rmtree(self._path)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 326, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 406, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 362, in iter\n",
      "    raise retry_exc.reraise()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 195, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 425, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\concurrent\\futures\\_base.py\", line 384, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 409, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 135, in rmtree\n",
      "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 500, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 390, in _rmtree_unsafe\n",
      "    _rmtree_unsafe(fullname, onerror)\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 395, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"C:\\Users\\danca\\anaconda3\\envs\\Arkenews\\lib\\shutil.py\", line 393, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\danca\\\\AppData\\\\Local\\\\Temp\\\\pip-install-eiyp_av1\\\\wrapt_dfb37ee308494fc1a1374030184c4895\\\\setup.py'\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvO3paY99BYU",
    "outputId": "df038911-19e6-4132-87b6-9ab38348d6e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "%tensorflow_version 1x\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_teIqQiF-ri3",
    "outputId": "daa7d899-d3d2-4d31-a26d-1fb6cdd3314a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-tensorflow==1.0.1 in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\danca\\anaconda3\\envs\\arkenews\\lib\\site-packages (from bert-tensorflow==1.0.1) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-tensorflow==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3nrJPiSgAEWU",
    "outputId": "44cc4695-624c-4ace-b475-0a82c7b36737"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-ee90c7bde93d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbert\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun_classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\bert\\run_classifier.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Arkenews\\lib\\site-packages\\bert\\modeling.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "import re \n",
    "\n",
    "def cleanUpTweet(txt):\n",
    "    # Remove mentions\n",
    "    txt = re.sub(r'@+', '', txt)\n",
    "    # Remove hashtags\n",
    "    txt = re.sub(r'#[A-Z0-9]+', '', txt)\n",
    "    # Remove retweets:\n",
    "    txt = re.sub(r'RT : ', '', txt)\n",
    "    # Remove urls\n",
    "    txt = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', txt)\n",
    "    #remove amp\n",
    "    txt = re.sub(r'&amp;', '', txt)\n",
    "    #rempve strange characters\n",
    "    txt = re.sub(r'ðŸ™', '', txt)\n",
    "    #remove new lines\n",
    "    txt = re.sub(r'\\n', ' ', txt)\n",
    "    return txt\n",
    "\n",
    "df_final['Cleaned_Tweet'] = df_final['Tweet'].apply(cleanUpTweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qtuAb680ALdg",
    "outputId": "c8958220-d008-4e5a-caf0-ce345b14a580"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-52383e53-94f3-47e2-97f2-fec72afb5131\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "      <th>Title</th>\n",
       "      <th>Country</th>\n",
       "      <th>Cleaned_Tweet</th>\n",
       "      <th>Label_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>I didn't ask for a pardon.\\n\\nBut a certain Pr...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>I didn't ask for a pardon.  But a certain Pres...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>Your daily reminder that instead of saying som...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>Your daily reminder that instead of saying som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>I’m proud to work with my Congressional collea...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>I’m proud to work with my Congressional collea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>RT @grantstern: Multiple Republican Congressme...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>RT grantstern: Multiple Republican Congressmen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RepAdams</td>\n",
       "      <td>RT @MacFarlaneNews: Approx. 140 police officer...</td>\n",
       "      <td>D</td>\n",
       "      <td>HOR</td>\n",
       "      <td>US</td>\n",
       "      <td>RT MacFarlaneNews: Approx. 140 police officers...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52383e53-94f3-47e2-97f2-fec72afb5131')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-52383e53-94f3-47e2-97f2-fec72afb5131 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-52383e53-94f3-47e2-97f2-fec72afb5131');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       User                                              Tweet Label Title  \\\n",
       "0  RepAdams  I didn't ask for a pardon.\\n\\nBut a certain Pr...     D   HOR   \n",
       "1  RepAdams  Your daily reminder that instead of saying som...     D   HOR   \n",
       "2  RepAdams  I’m proud to work with my Congressional collea...     D   HOR   \n",
       "3  RepAdams  RT @grantstern: Multiple Republican Congressme...     D   HOR   \n",
       "4  RepAdams  RT @MacFarlaneNews: Approx. 140 police officer...     D   HOR   \n",
       "\n",
       "  Country                                      Cleaned_Tweet  Label_Number  \n",
       "0      US  I didn't ask for a pardon.  But a certain Pres...             1  \n",
       "1      US  Your daily reminder that instead of saying som...             1  \n",
       "2      US  I’m proud to work with my Congressional collea...             1  \n",
       "3      US  RT grantstern: Multiple Republican Congressmen...             1  \n",
       "4      US  RT MacFarlaneNews: Approx. 140 police officers...             1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode Label: D = 1 / R = 0\n",
    "\n",
    "df_final['Label_Number'] = df_final.Label.map({'R':0, 'D':1})\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "emC7otg5L4_c"
   },
   "outputs": [],
   "source": [
    " train = df_final\n",
    "test =  df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IgXB6-Uz8i1N"
   },
   "outputs": [],
   "source": [
    "# train = train.sample(5000)\n",
    "# test = test.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KfNeKUY58i4h"
   },
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'Cleaned_Tweet'\n",
    "LABEL_COLUMN = 'Label_Number'\n",
    "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "label_list = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "crQwuMij8i7g"
   },
   "outputs": [],
   "source": [
    "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0PczIhAOkVU",
    "outputId": "0c9b1b71-d0b1-496f-c939-ac68158d9436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-l-xSHIMOkYU",
    "outputId": "c71d89ac-e75b-40e1-b32e-a501604befda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i didn ' t ask for a pardon . but a certain president who \" engaged in insurrection or rebellion against the [ united states ] , or given aid or comfort to the enemies thereof \" may need to ask both houses of congress to restore their ability to hold office , per the 14th amendment . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i didn ' t ask for a pardon . but a certain president who \" engaged in insurrection or rebellion against the [ united states ] , or given aid or comfort to the enemies thereof \" may need to ask both houses of congress to restore their ability to hold office , per the 14th amendment . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2134 1005 1056 3198 2005 1037 14933 1012 2021 1037 3056 2343 2040 1000 5117 1999 27860 2030 7417 2114 1996 1031 2142 2163 1033 1010 2030 2445 4681 2030 7216 2000 1996 6716 21739 1000 2089 2342 2000 3198 2119 3506 1997 3519 2000 9239 2037 3754 2000 2907 2436 1010 2566 1996 6400 7450 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2134 1005 1056 3198 2005 1037 14933 1012 2021 1037 3056 2343 2040 1000 5117 1999 27860 2030 7417 2114 1996 1031 2142 2163 1033 1010 2030 2445 4681 2030 7216 2000 1996 6716 21739 1000 2089 2342 2000 3198 2119 3506 1997 3519 2000 9239 2037 3754 2000 2907 2436 1010 2566 1996 6400 7450 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] your daily reminder that instead of saying something trans ##phobic or homo ##phobic to a student or neighbor , you could always just be quiet . . . . . . or even better , an ally . empathy and basic human dec ##ency shouldn ' t be this hard . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] your daily reminder that instead of saying something trans ##phobic or homo ##phobic to a student or neighbor , you could always just be quiet . . . . . . or even better , an ally . empathy and basic human dec ##ency shouldn ' t be this hard . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2115 3679 14764 2008 2612 1997 3038 2242 9099 20200 2030 24004 20200 2000 1037 3076 2030 11429 1010 2017 2071 2467 2074 2022 4251 1012 1012 1012 1012 1012 1012 2030 2130 2488 1010 2019 9698 1012 26452 1998 3937 2529 11703 11916 5807 1005 1056 2022 2023 2524 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2115 3679 14764 2008 2612 1997 3038 2242 9099 20200 2030 24004 20200 2000 1037 3076 2030 11429 1010 2017 2071 2467 2074 2022 4251 1012 1012 1012 1012 1012 1012 2030 2130 2488 1010 2019 9698 1012 26452 1998 3937 2529 11703 11916 5807 1005 1056 2022 2023 2524 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i ’ m proud to work with my congressional colleagues , the administration , and stakeholders like attorney general josh ##stein _ to an ##cel ##st ##ude ##nt ##de ##bt - especially debt from for - profit institutions that def ##ra ##uded students and borrow ##ers alike . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i ’ m proud to work with my congressional colleagues , the administration , and stakeholders like attorney general josh ##stein _ to an ##cel ##st ##ude ##nt ##de ##bt - especially debt from for - profit institutions that def ##ra ##uded students and borrow ##ers alike . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 1521 1049 7098 2000 2147 2007 2026 7740 8628 1010 1996 3447 1010 1998 22859 2066 4905 2236 6498 8602 1035 2000 2019 29109 3367 12672 3372 3207 19279 1011 2926 7016 2013 2005 1011 5618 4896 2008 13366 2527 13936 2493 1998 17781 2545 11455 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 1521 1049 7098 2000 2147 2007 2026 7740 8628 1010 1996 3447 1010 1998 22859 2066 4905 2236 6498 8602 1035 2000 2019 29109 3367 12672 3372 3207 19279 1011 2926 7016 2013 2005 1011 5618 4896 2008 13366 2527 13936 2493 1998 17781 2545 11455 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] rt grants ##tern : multiple republican congress ##men contacted the white house seeking pardon ##s for their roles in january 6th . that is a bombs ##h … [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] rt grants ##tern : multiple republican congress ##men contacted the white house seeking pardon ##s for their roles in january 6th . that is a bombs ##h … [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 19387 8624 16451 1024 3674 3951 3519 3549 11925 1996 2317 2160 6224 14933 2015 2005 2037 4395 1999 2254 5351 1012 2008 2003 1037 9767 2232 1529 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 19387 8624 16451 1024 3674 3951 3519 3549 11925 1996 2317 2160 6224 14933 2015 2005 2037 4395 1999 2254 5351 1012 2008 2003 1037 9767 2232 1529 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] rt mac ##farlane ##ne ##ws : approx . 140 police officers were injured on jan 6 , 2021 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] rt mac ##farlane ##ne ##ws : approx . 140 police officers were injured on jan 6 , 2021 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 19387 6097 23511 2638 9333 1024 22480 1012 8574 2610 3738 2020 5229 2006 5553 1020 1010 25682 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 19387 6097 23511 2638 9333 1024 22480 1012 8574 2610 3738 2020 5229 2006 5553 1020 1010 25682 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 20000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 20000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 30000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 30000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 40000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 40000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 50000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 50000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 60000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 60000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 70000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 70000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 80000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 80000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 90000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 90000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 100000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 100000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 110000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 110000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 120000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 120000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i didn ' t ask for a pardon . but a certain president who \" engaged in insurrection or rebellion against the [ united states ] , or given aid or comfort to the enemies thereof \" may need to ask both houses of congress to restore their ability to hold office , per the 14th amendment . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i didn ' t ask for a pardon . but a certain president who \" engaged in insurrection or rebellion against the [ united states ] , or given aid or comfort to the enemies thereof \" may need to ask both houses of congress to restore their ability to hold office , per the 14th amendment . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2134 1005 1056 3198 2005 1037 14933 1012 2021 1037 3056 2343 2040 1000 5117 1999 27860 2030 7417 2114 1996 1031 2142 2163 1033 1010 2030 2445 4681 2030 7216 2000 1996 6716 21739 1000 2089 2342 2000 3198 2119 3506 1997 3519 2000 9239 2037 3754 2000 2907 2436 1010 2566 1996 6400 7450 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2134 1005 1056 3198 2005 1037 14933 1012 2021 1037 3056 2343 2040 1000 5117 1999 27860 2030 7417 2114 1996 1031 2142 2163 1033 1010 2030 2445 4681 2030 7216 2000 1996 6716 21739 1000 2089 2342 2000 3198 2119 3506 1997 3519 2000 9239 2037 3754 2000 2907 2436 1010 2566 1996 6400 7450 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] your daily reminder that instead of saying something trans ##phobic or homo ##phobic to a student or neighbor , you could always just be quiet . . . . . . or even better , an ally . empathy and basic human dec ##ency shouldn ' t be this hard . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] your daily reminder that instead of saying something trans ##phobic or homo ##phobic to a student or neighbor , you could always just be quiet . . . . . . or even better , an ally . empathy and basic human dec ##ency shouldn ' t be this hard . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2115 3679 14764 2008 2612 1997 3038 2242 9099 20200 2030 24004 20200 2000 1037 3076 2030 11429 1010 2017 2071 2467 2074 2022 4251 1012 1012 1012 1012 1012 1012 2030 2130 2488 1010 2019 9698 1012 26452 1998 3937 2529 11703 11916 5807 1005 1056 2022 2023 2524 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2115 3679 14764 2008 2612 1997 3038 2242 9099 20200 2030 24004 20200 2000 1037 3076 2030 11429 1010 2017 2071 2467 2074 2022 4251 1012 1012 1012 1012 1012 1012 2030 2130 2488 1010 2019 9698 1012 26452 1998 3937 2529 11703 11916 5807 1005 1056 2022 2023 2524 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i ’ m proud to work with my congressional colleagues , the administration , and stakeholders like attorney general josh ##stein _ to an ##cel ##st ##ude ##nt ##de ##bt - especially debt from for - profit institutions that def ##ra ##uded students and borrow ##ers alike . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i ’ m proud to work with my congressional colleagues , the administration , and stakeholders like attorney general josh ##stein _ to an ##cel ##st ##ude ##nt ##de ##bt - especially debt from for - profit institutions that def ##ra ##uded students and borrow ##ers alike . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 1521 1049 7098 2000 2147 2007 2026 7740 8628 1010 1996 3447 1010 1998 22859 2066 4905 2236 6498 8602 1035 2000 2019 29109 3367 12672 3372 3207 19279 1011 2926 7016 2013 2005 1011 5618 4896 2008 13366 2527 13936 2493 1998 17781 2545 11455 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 1521 1049 7098 2000 2147 2007 2026 7740 8628 1010 1996 3447 1010 1998 22859 2066 4905 2236 6498 8602 1035 2000 2019 29109 3367 12672 3372 3207 19279 1011 2926 7016 2013 2005 1011 5618 4896 2008 13366 2527 13936 2493 1998 17781 2545 11455 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] rt grants ##tern : multiple republican congress ##men contacted the white house seeking pardon ##s for their roles in january 6th . that is a bombs ##h … [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] rt grants ##tern : multiple republican congress ##men contacted the white house seeking pardon ##s for their roles in january 6th . that is a bombs ##h … [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 19387 8624 16451 1024 3674 3951 3519 3549 11925 1996 2317 2160 6224 14933 2015 2005 2037 4395 1999 2254 5351 1012 2008 2003 1037 9767 2232 1529 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 19387 8624 16451 1024 3674 3951 3519 3549 11925 1996 2317 2160 6224 14933 2015 2005 2037 4395 1999 2254 5351 1012 2008 2003 1037 9767 2232 1529 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] rt mac ##farlane ##ne ##ws : approx . 140 police officers were injured on jan 6 , 2021 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] rt mac ##farlane ##ne ##ws : approx . 140 police officers were injured on jan 6 , 2021 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 19387 6097 23511 2638 9333 1024 22480 1012 8574 2610 3738 2020 5229 2006 5553 1020 1010 25682 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 19387 6097 23511 2638 9333 1024 22480 1012 8574 2610 3738 2020 5229 2006 5553 1020 1010 25682 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 20000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 20000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 30000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 30000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 40000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 40000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 50000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 50000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 60000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 60000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 70000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 70000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 80000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 80000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 90000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 90000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 100000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 100000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 110000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 110000 of 120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 120000 of 120218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 120000 of 120218\n"
     ]
    }
   ],
   "source": [
    "# We'll set sequences to be at most 128 tokens long.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "R57aVXcwOkbU"
   },
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZhyAxgzUOkeM"
   },
   "outputs": [],
   "source": [
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        f1_score = tf.contrib.metrics.f1_score(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        auc = tf.metrics.auc(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        recall = tf.metrics.recall(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        precision = tf.metrics.precision(\n",
    "            label_ids,\n",
    "            predicted_labels) \n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"auc\": auc,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg\n",
    "        }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ny0Y4mRPOkgz"
   },
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OOTAe9rgPJbv"
   },
   "outputs": [],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "u25YSa3FUMBO"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ScfVkHuuPTTQ",
    "outputId": "bbcd7159-dc9b-487f-c6a0-38ea3beb26bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=\n",
    "print(os.path.join('C:',os.sep, 'Users')),\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfcYB9HhPfTJ",
    "outputId": "9f308b9f-e82a-4994-f810-623a0e978e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp8yde5t3v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp8yde5t3v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp8yde5t3v', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f28d106c950>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp8yde5t3v', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f28d106c950>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "  \n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zlmn_mPrP-qh"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# def model_train(estimator):\n",
    "#   print('MRPC/CoLA on BERT base model normally takes about 2-3 minutes. Please wait...')\n",
    "#   # We'll set sequences to be at most 128 tokens long.\n",
    "#   train_features = run_classifier.convert_examples_to_features(\n",
    "#       train, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "#   print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
    "#   print('  Num examples = {}'.format(len(train)))\n",
    "#   print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
    "#   tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "#   train_input_fn = run_classifier.input_fn_builder(\n",
    "#       features=train_features,\n",
    "#       seq_length=MAX_SEQ_LENGTH,\n",
    "#       is_training=True,\n",
    "#       drop_remainder=True)\n",
    "#   estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "#   print('***** Finished training at {} *****'.format(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "TyDQzlBXTYuD"
   },
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "lMjCCgzJPfZL",
    "outputId": "126cf4e5-f2e5-4456-e8be-a72ce78157d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6187edf75f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Beginning Training!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcurrent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training took time \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DASKq0LCPfb8"
   },
   "outputs": [],
   "source": [
    "test_input_fn = run_classifier.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSHMpCpYPfe6"
   },
   "outputs": [],
   "source": [
    "estimator.evaluate(input_fn=test_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vhad87sjPfhq"
   },
   "outputs": [],
   "source": [
    "def getPrediction(in_sentences):\n",
    "  labels = [\"Not Democratic\", \"Democratic\"]\n",
    "  input_examples = [run_classifier.InputExample(guid=None, text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
    "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGnx_TAyP9KS"
   },
   "outputs": [],
   "source": [
    "getPrediction(\"universal healthcare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hm3mkmKOm5oI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FeblPoR7m5vw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAT3j4dWm5yj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OfnDdgWm51g"
   },
   "outputs": [],
   "source": [
    "ffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_WiOSwOm54L"
   },
   "outputs": [],
   "source": [
    "ff"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ARKENEWS BERT DANIEL FACI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
